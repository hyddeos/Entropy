<script>

</script>

<div class="max-w-2xl p-2 m-auto">
    <h3 class="text-2xl my-2 font-bold underline decoration-success">The Math</h3>
    <p class="my-1">*This is calculated with this formula:</p>
    <img class="m-auto my-2" src="/images/formula.svg" alt="img of the formula">
    <p class="my-1 m-auto text-center"><strong class="font-bold text-primary italic">n</strong> Total number of particles</p>
    <p class="my-1 m-auto text-center"><strong class="font-bold text-primary italic">r</strong> Number particles in one box</p>
    <div class="my-2"></div> 
    <p class="my-1">That's the number of possible ways to rearrange the particles without
        changing the overall state(ie maintaining the same number of particles in the boxes).
    </p>
    <p class="my-1"><strong class="bold">For example:</strong> There is only one way all particles can be in one box, as soon as one particle is in another box the state is not the same.
        But if you have one particle in each box. The particles can swap places with each other
        and there overall state will still be the same, there for in that case there are 2 possible
        configurations.    
    </p>
</div>
<div class="max-w-2xl p-2 m-auto">
    <h3 class="text-2xl my-2 font-bold underline decoration-secondary">What Is Entropy?</h3>
    <h2 class="text-xl font-bold my-2">In Short</h2>
    <p class="my-1">
        Entropy is a measure of disorder or randomness in a system. In other words, 
        it is a measure of the amount of uncertainty or unpredictability in a system. 
        The more disordered a system is, the higher its entropy will be. For example, 
        a deck of cards that is shuffled well will have a higher entropy than a deck of 
        cards that is not shuffled. In a more general sense, entropy can be thought of as a 
        measure of how spread out the energy or matter in a system is. For example, a gas that
         is evenly distributed throughout a container will have a higher entropy than a gas that 
         is concentrated in one part of the container.
    </p>
    <h2 class="text-xl font-bold my-2">Deeper Dive</h2>
    <p class="my-1">Entropy, It is a fundamental concept in the field of thermodynamics, 
        which deals with the behavior of energy and matter. In this context, entropy is a measure of the 
        disorder or randomness of a system, and is closely related to the concept of probability. 
        In a universe that is governed by the laws of thermodynamics, entropy will always increase over time, 
        as energy and matter become more and more dispersed and disordered. 
        This can be seen as a natural consequence of the inherent uncertainty and randomness of the universe.</p>
        <p class="my-1">You can find examples of entropy in your everyday experience in many different ways.</p>
        <p class="font-bold my-2"> Here are a few examples: </p>
        <ul class="list-disc list-outside px-4">
            <li class="my-1">When you open a box that has been sealed for a long time, the air inside the box will rush out, spreading into the surrounding environment. This is an example of entropy, as the air molecules inside the box were initially concentrated in one place (the box), but are now more dispersed in the environment.</li>
            <li class="my-1">When you shuffle a deck of cards, the cards will become more random and disordered. This is an example of entropy, as the cards were initially in a predictable order (e.g. Ace of Spades, Two of Spades, Three of Spades, etc.), but are now more randomly arranged.</li>
            <li class="my-1">When you pour a liquid (like water) into a container, it will naturally spread out to fill the container. This is also an example of entropy, as the molecules of the liquid were initially concentrated in one place (the container), but are now more dispersed throughout the container.</li>
        </ul>
</div>
